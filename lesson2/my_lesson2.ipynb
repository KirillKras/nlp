{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet  \\\nid                                                             \n1     0.0   @user when a father is dysfunctional and is s...   \n2     0.0  @user @user thanks for #lyft credit i can't us...   \n3     0.0                                bihday your majesty   \n4     0.0  #model   i love u take with u all the time in ...   \n5     0.0             factsguide: society now    #motivation   \n\n                                          clean_tweet  \\\nid                                                      \n1   when father is dysfunctional and is so selfish...   \n2   thanks for lyft credit can not use cause they ...   \n3                                 bihday your majesty   \n4             model love take with all the time in ur   \n5                   factsguide society now motivation   \n\n                                          tweet_token  \\\nid                                                      \n1   [when, father, is, dysfunctional, and, is, so,...   \n2   [thanks, for, lyft, credit, can, not, use, cau...   \n3                             [bihday, your, majesty]   \n4   [model, love, take, with, all, the, time, in, ur]   \n5              [factsguide, society, now, motivation]   \n\n                                 tweet_token_filtered  \\\nid                                                      \n1   [father, dysfunctional, selfish, drags, kids, ...   \n2   [thanks, lyft, credit, use, cause, offer, whee...   \n3                                   [bihday, majesty]   \n4                       [model, love, take, time, ur]   \n5                   [factsguide, society, motivation]   \n\n                                        tweet_stemmed  \nid                                                     \n1   [father, dysfunctional, selfish, drag, kid, dy...  \n2   [thanks, lyft, credit, use, cause, offer, whee...  \n3                                   [bihday, majesty]  \n4                       [model, love, take, time, ur]  \n5                   [factsguide, society, motivation]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>clean_tweet</th>\n      <th>tweet_token</th>\n      <th>tweet_token_filtered</th>\n      <th>tweet_stemmed</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n      <td>when father is dysfunctional and is so selfish...</td>\n      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n      <td>thanks for lyft credit can not use cause they ...</td>\n      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n      <td>bihday your majesty</td>\n      <td>[bihday, your, majesty]</td>\n      <td>[bihday, majesty]</td>\n      <td>[bihday, majesty]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n      <td>model love take with all the time in ur</td>\n      <td>[model, love, take, with, all, the, time, in, ur]</td>\n      <td>[model, love, take, time, ur]</td>\n      <td>[model, love, take, time, ur]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>factsguide: society now    #motivation</td>\n      <td>factsguide society now motivation</td>\n      <td>[factsguide, society, now, motivation]</td>\n      <td>[factsguide, society, motivation]</td>\n      <td>[factsguide, society, motivation]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('tweets')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Создайте мешок слов CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-feb5bb9f524d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mcount_vector\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCountVectorizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_df\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.9\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_features\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_words\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'english'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mbag_stemmed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcount_vector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'tweet_stemmed'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mfeature_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcount_vector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_feature_names\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mdf_stemmed_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbag_stemmed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfeature_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mmax_features\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_features\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1197\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1198\u001B[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001B[0m\u001B[1;32m   1199\u001B[0m                                           self.fixed_vocabulary_)\n\u001B[1;32m   1200\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_count_vocab\u001B[0;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[1;32m   1108\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mraw_documents\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1109\u001B[0m             \u001B[0mfeature_counter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1110\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mfeature\u001B[0m \u001B[0;32min\u001B[0m \u001B[0manalyze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1111\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1112\u001B[0m                     \u001B[0mfeature_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvocabulary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_analyze\u001B[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mpreprocessor\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m             \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpreprocessor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m             \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_preprocess\u001B[0;34m(doc, accent_function, lower)\u001B[0m\n\u001B[1;32m     67\u001B[0m     \"\"\"\n\u001B[1;32m     68\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlower\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 69\u001B[0;31m         \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdoc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     70\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0maccent_function\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maccent_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "count_vector = CountVectorizer(max_df=0.9, max_features=1000, stop_words='english')\n",
    "bag_stemmed = count_vector.fit_transform(df['tweet_stemmed'])\n",
    "feature_names = count_vector.get_feature_names()\n",
    "df_stemmed_count = pd.DataFrame(bag_stemmed.toarray(), columns = feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "count_vector =  CountVectorizer(max_df=0.9, max_features=1000, stop_words='english')\n",
    "bag_lemmatize = count_vector.fit_transform(df['tweet_lemmatize'])\n",
    "feature_names = count_vector.get_feature_names()\n",
    "df_lemmatize_count = pd.DataFrame(bag_lemmatize.toarray(), columns = feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Создайте мешок слов TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english')\n",
    "bag_stemmed = tfidf_vector.fit_transform(df['tweet_stemmed'])\n",
    "feature_names = tfidf_vector.get_feature_names()\n",
    "df_stemmed_tfidf = pd.DataFrame(bag_stemmed.toarray(), columns = feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english')\n",
    "bag_lemmatize = tfidf_vector.fit_transform(df['tweet_lemmatize'])\n",
    "feature_names = tfidf_vector.get_feature_names()\n",
    "df_lemmatize_tfidf = pd.DataFrame(bag_lemmatize.toarray(), columns = feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Натренируем gensim.models.Word2Vec модель на наших данных."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "model = Word2Vec(size=200, window=5, min_count=2, sg = 1, hs = 0,\n",
    "                 negative = 10, workers= 32, seed = 34)\n",
    "model.build_vocab(df['tweet_token'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "(18169952, 102218480)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences=df['tweet_token'], total_examples=df['tweet_token'].shape[0], epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-37ff56d1ad61>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model.most_similar('dinner')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'dinner' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-58-37ff56d1ad61>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmost_similar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'dinner'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/utils.py\u001B[0m in \u001B[0;36mnew_func1\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1459\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1460\u001B[0m                 )\n\u001B[0;32m-> 1461\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1462\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1463\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mnew_func1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001B[0m in \u001B[0;36mmost_similar\u001B[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001B[0m\n\u001B[1;32m   1381\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1382\u001B[0m         \"\"\"\n\u001B[0;32m-> 1383\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmost_similar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositive\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnegative\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrestrict_vocab\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1384\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1385\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mdeprecated\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mmost_similar\u001B[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001B[0m\n\u001B[1;32m    551\u001B[0m                 \u001B[0mmean\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 553\u001B[0;31m                 \u001B[0mmean\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mword_vec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_norm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    554\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mword\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvocab\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    555\u001B[0m                     \u001B[0mall_words\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvocab\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mword\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mword_vec\u001B[0;34m(self, word, use_norm)\u001B[0m\n\u001B[1;32m    466\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    467\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 468\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"word '%s' not in vocabulary\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    469\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    470\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_vector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"word 'dinner' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.most_similar('dinner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "31"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "l = df['tweet_token'].tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(l[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dtype '<class 'list'>' not understood",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-73-c04d3cf4534d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'tweet_token'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'tweet_token'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m   5544\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5545\u001B[0m             \u001B[0;31m# else, only a single dtype is given\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5546\u001B[0;31m             \u001B[0mnew_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5547\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_constructor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"astype\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5548\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    593\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"raise\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    594\u001B[0m     ) -> \"BlockManager\":\n\u001B[0;32m--> 595\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"astype\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    596\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m     def convert(\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[1;32m    404\u001B[0m                 \u001B[0mapplied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    405\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 406\u001B[0;31m                 \u001B[0mapplied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    407\u001B[0m             \u001B[0mresult_blocks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_extend_blocks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapplied\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult_blocks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    408\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    546\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    547\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 548\u001B[0;31m             \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpandas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    549\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    550\u001B[0m         \u001B[0;31m# may need to convert to categorical\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001B[0m in \u001B[0;36mpandas_dtype\u001B[0;34m(dtype)\u001B[0m\n\u001B[1;32m   1776\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mnpdtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1777\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mnpdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"O\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1778\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"dtype '{dtype}' not understood\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1779\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1780\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mnpdtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: dtype '<class 'list'>' not understood"
     ]
    }
   ],
   "source": [
    "df['tweet_token'] = df['tweet_token'].astype(list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "['when',\n 'father',\n 'is',\n 'dysfunctional',\n 'and',\n 'is',\n 'so',\n 'selfish',\n 'he',\n 'drags',\n 'his',\n 'kids',\n 'into',\n 'his',\n 'dysfunction',\n 'run']"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in nltk.tokenize.word_tokenize(df['clean_tweet'].iloc[0])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}